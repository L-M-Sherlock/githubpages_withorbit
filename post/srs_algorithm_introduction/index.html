<!doctype html><html lang=zh-hans><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=HandheldFriendly content="True"><meta http-equiv=x-ua-compatible content="IE=edge"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=generator content="Hugo 0.95.0"><link rel=apple-touch-icon sizes=180x180 href=http://l-m-sherlock.github.io/githubpages_withorbit/icons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=http://l-m-sherlock.github.io/githubpages_withorbit/icons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=http://l-m-sherlock.github.io/githubpages_withorbit/icons/favicon-16x16.png><link rel=manifest href=http://l-m-sherlock.github.io/githubpages_withorbit/icons/site.webmanifest><link rel=mask-icon href=http://l-m-sherlock.github.io/githubpages_withorbit/icons/safari-pinned-tab.svg color=#000000><link rel="shortcut icon" href=http://l-m-sherlock.github.io/githubpages_withorbit/icons/favicon.ico><meta name=msapplication-TileColor content="#ffc40d"><meta name=msapplication-config content="http://l-m-sherlock.github.io/githubpages_withorbit/icons/browserconfig.xml"><meta name=theme-color content="#ffffff"><title>记忆算法：3天内，从入门到入土 - Spaced Repetition in Mnemonic Medium</title><meta name=author content="Jarrett Ye"><meta name=description content="Introduce spaced repetition via mnemonic medium."><meta name=keywords content="间隔重复,原创"><meta property="og:title" content="记忆算法：3天内，从入门到入土"><meta name=twitter:title content="记忆算法：3天内，从入门到入土"><meta property="og:type" content="article"><meta property="og:url" content="https://l-m-sherlock.github.io/githubpages_withorbit/post/srs_algorithm_introduction/"><meta property="og:description" content="一份不太简短的记忆算法介绍（尚未定稿）"><meta name=twitter:description content="一份不太简短的记忆算法介绍（尚未定稿）"><meta property="og:image" content="https://l-m-sherlock.github.io/githubpages_withorbit/og.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://l-m-sherlock.github.io/githubpages_withorbit/og.png"><meta property="article:published_time" content="2022-03-23T10:59:12+08:00"><meta property="article:modified_time" content="2022-03-23T10:59:12+08:00"><style>@media(prefers-color-scheme:dark){body[data-theme=auto] img{filter:brightness(60%)}}body[data-theme=dark] img{filter:brightness(60%)}</style><link rel=stylesheet href=https://l-m-sherlock.github.io/githubpages_withorbit/assets/css/fuji.min.css></head><body data-theme=auto data-theme-auto=true><script data-cfasync=false>var fujiThemeData=localStorage.getItem("fuji_data-theme");fujiThemeData?fujiThemeData!=="auto"&&document.body.setAttribute("data-theme",fujiThemeData==="dark"?"dark":"light"):localStorage.setItem("fuji_data-theme","auto")</script><header><div class="container-lg clearfix"><div class="col-12 header"><a class=title-main href=https://l-m-sherlock.github.io/githubpages_withorbit/>Spaced Repetition in Mnemonic Medium</a>
<span class=title-sub>用助记媒介，介绍间隔重复！</span></div></div></header><main><div class="container-lg clearfix"><div class="col-12 col-md-9 float-left content"><article><h2 class="post-item post-title"><a href=https://l-m-sherlock.github.io/githubpages_withorbit/post/srs_algorithm_introduction/>记忆算法：3天内，从入门到入土</a></h2><div class="post-item post-meta"><span><i class="iconfont icon-today-sharp"></i>&nbsp;2022-03-23</span>
<span><i class="iconfont icon-file-tray-sharp"></i>&nbsp;5572 字</span>
<span><i class="iconfont icon-time-sharp"></i>&nbsp;12 分钟</span>
<span><i class="iconfont icon-pricetags-sharp"></i>&nbsp;<a href=/githubpages_withorbit/tags/%E9%97%B4%E9%9A%94%E9%87%8D%E5%A4%8D>间隔重复</a>&nbsp;<a href=/githubpages_withorbit/tags/%E5%8E%9F%E5%88%9B>原创</a>&nbsp;</span></div><div class="post-content markdown-body"><p>一份不太简短的记忆算法介绍（尚未定稿）</p><h2 id=引言>引言</h2><blockquote><p>《记忆算法：3天内，从入门到入土》改编自我在墨墨背单词内部介绍记忆算法的手稿，希望能让大家了解记忆算法到底在研究些什么。废话不多说，让我们开始吧～</p></blockquote><p>从学生时代起，我们就隐隐约约察觉到以下两个事实</p><ol><li>对一条知识多复习几次，就能记得更清楚。</li><li>不同的记忆有不同的寿命（记住一组知识后，它们将一条一条被遗忘，而不是作为一个整体完全丢失）</li></ol><p>这两个事实常常引发我们思考</p><ol><li>此刻的我们忘掉了多少知识？</li><li>我们遗忘知识的速度有多快？</li><li>怎样安排复习才能减少遗忘？</li></ol><p>在过去，很少人去测量过这些指标，也少有人去根据具体的指标来安排复习。而记忆算法要研究的，正是如何描述与预测我们的记忆，并做出合理的复习安排。</p><p>接下来的三天，我们将从以下三个方面来了解记忆算法</p><ol><li>经验算法</li><li>理论模型</li><li>前沿进展</li></ol><p>为了让大家能更轻松地吸收这些知识，我在文章中嵌入不少助记卡片，不妨试试回答上面的问题。</p><h2 id=day-1-经验算法>Day 1 经验算法</h2><p>今天我们从最简单的经验算法讲起，了解一下目前还在流行的一些算法细节和它们背后的思想。不过在此之前，我们先讲讲这些算法的通用名称——间隔重复——的由来。</p><h3 id=间隔重复>间隔重复</h3><p>为了方便没有任何记忆相关基础知识的读者，我们先来认识一下遗忘曲线：</p><p><img class=img-zoomable src=/githubpages_withorbit/%e9%81%97%e5%bf%98%e6%9b%b2%e7%ba%bf.jpg alt=遗忘曲线></p><p>第一天，当我们翻开课本，听老师讲课，学了点东西之后，随着时间推移，我们学到的东西在记忆中的保留量将像遗忘曲线那样持续下降。</p><p>遗忘曲线是对知识在我们记忆中的保留情况进行描述，其特点也非常鲜明：在没有进行复习的情况下，记忆保留随着时间下降的程度是先快后慢的。</p><p>面对遗忘我们怎能坐以待毙？看看加入复习后的效果！</p><p><img class=img-zoomable src=/githubpages_withorbit/%e9%95%bf%e6%9c%9f%e8%ae%b0%e5%bf%86.jpg alt=长期记忆></p><p>在学习新知识之后的这段时间里，如果我们进行复习，然后用一条新的遗忘曲线来刻画复习后的记忆保留情况，就会看到，复习之后的遗忘曲线变得更加平缓了，这意味着遗忘的速度在变慢。</p><p>那么问题来了，我们该怎样安排复习的间隔，才能更高效地记忆？</p><p><img class=img-zoomable src=/githubpages_withorbit/%e4%bd%95%e6%97%b6%e5%a4%8d%e4%b9%a0.jpg alt=何时复习></p><p>看到一长一短的两个间隔了吗？对于较为生疏的材料，我们加以较短的间隔，而对于较为熟悉的材料，我们加以较长的间隔，将复习分散到未来不同的时间点进行。这种增强长期记忆的方法，被称为间隔重复。</p><p>那么间隔重复效果究竟有多好呢？让我们看一组医学生的数据：</p><p><img class=img-zoomable src=/githubpages_withorbit/%e6%8f%90%e9%ab%98%e6%95%88%e7%8e%87.jpg alt=提高效率></p><p>没有间隔重复，学生将在一年后遗忘 33% 的知识，两年后遗忘 50%！使用间隔重复后，将提高 40% 的学习效率！</p><p>既然间隔重复的效果这么好，那为什么它没有得到推广呢？</p><p><img class=img-zoomable src=/githubpages_withorbit/%e5%a4%a7%e9%87%8f%e5%8d%a1%e7%89%87.jpg alt=大量卡片></p><p>因为要学的知识太多了！而且每个知识都有自己的遗忘曲线，想要去追踪他们的复习时机并安排间隔重复是很难的。</p><p>这就引出了记忆算法的用途：自动化地跟踪知识的记忆状态，并安排高效的复习计划。</p><p>相信你对间隔重复已经有了初步的理解，不过肯定还会有不少疑问，比如复习时机是如何计算的，怎样间隔重复才是高效的。对于这些问题的解答，都在之后的章节中。让我们进入正题吧！</p><orbit-reviewarea><orbit-prompt question=遗忘曲线刻画了什么？ answer=随着时间推移，知识在我们记忆中的保留情况></orbit-prompt>
<orbit-prompt question=在没有进行复习的情况下，记忆保留的下降速度呈什么变化？ answer=先快后慢></orbit-prompt>
<orbit-prompt question=在复习之后，新的遗忘曲线相比旧的遗忘曲线，有什么区别？ answer=新的遗忘曲线更平，即遗忘得更慢></orbit-prompt>
<orbit-prompt question=间隔重复的复习安排有什么特点？ answer=复习被分散到未来不同的时间点></orbit-prompt>
<orbit-prompt question=间隔重复如何区别对待不同记忆程度的内容 answer=生疏的材料用较短的间隔，熟悉的材料用较长的间隔></orbit-prompt>
<orbit-prompt question=间隔重复的对记忆的作用是什么？ answer=增强长期记忆></orbit-prompt>
<orbit-prompt question=记忆算法在间隔重复中扮演什么样的角色？ answer=跟踪记忆状态，自动安排复习计划></orbit-prompt></orbit-reviewarea><p>在了解了间隔重复的概念后，你很可能已经开始琢磨这句话了：</p><blockquote><p>对于较为生疏的材料，我们加以较短的间隔，而对于较为熟悉的材料，我们加以较长的间隔，将复习分散到未来不同的时间点进行。</p></blockquote><p>这个较短的间隔，和较长的间隔，究竟是多久？生疏和熟悉，又该如何判断？</p><p>凭借直觉，材料在我们记忆中的遗忘速度越慢，那便是越熟悉。而一个合理的间隔，应当尽可能减少我们的遗忘。但是想要遗忘得越少，从遗忘曲线中我们可以推理出，需要的间隔也越短。而间隔越短，复习的频率就会越高。</p><p>看来复习频率和遗忘率之间存在某种不可调和的矛盾，这可如何是好？</p><p>坐在电脑前空想，看来是得不出什么结论。我们现在对间隔重复的了解还是太少了。</p><p>如果让你来解决这个矛盾，你会需要继续了解什么？你会设计怎样的实验？保持对这些问题的思考，如果能写下来就更好了！</p><p>让我们开始看看首个间隔重复算法的设计者是怎样开始他的记忆算法研究之路吧！</p><h3 id=sm-0>SM-0</h3><p>1985年，年轻的大学生彼得·沃兹尼亚克（下文简称沃兹）正陷入遗忘的泥潭中：</p><p><img class=img-zoomable src=https://supermemo.guru/images/thumb/a/a9/English-Polish_word_pairs_%28Wozniak_1982%29.jpg/550px-English-Polish_word_pairs_%28Wozniak_1982%29.jpg alt="English-Polish word pairs (Wozniak 1982).jpg"></p><p>上面这张图片是沃兹的单词笔记本中的一页。79 页，总计 2794 个单词，每页约有 40 个英语-波兰语词对，如何管理它们的复习，让沃兹头疼不已。沃兹一开始没有任何规律的复习计划，复习任何一张笔记全取决于有没有足够的时间。但沃兹做了一件很重要的事情：记录了复习日期和遗忘数量。这使得他可以量化自己的复习情况。</p><p>他统计了一整年的复习记录，发现他的遗忘率差不多有 40%～60%。这是他难以接受的，他需要一个合理的复习时间表，能降低他的遗忘率，但不要带来太多的复习负担。为了找到合理的复习间隔，他开始了他自己的记忆实验。</p><p>沃兹对合理的复习间隔的期望是：尽可能长，但不要让遗忘率超过 5%</p><p>沃兹的实验如下：</p><p>实验材料：5 页英语-波兰语笔记，每页 40 个词对。</p><p>在第一个学习阶段中，将 5 页材料全部记住。具体的操作为：看英语，回想波兰语，然后检查是否回忆正确。如果回忆正确，将该词对剔除出本阶段。如果回忆失败，就在稍后重新回想，直到所有的回忆都正确为止。</p><p>然后是第一个复习阶段，沃兹直接选择了 1 天的间隔，这来自于他此前的复习经验。接下来是该实验最重要的 3 个阶段，记作 A、B、C。</p><p>A 阶段，5 页笔记分别间隔 2、4、6、8、10 天后进行第二次复习，统计得到的遗忘率分别为 0%、0%、0%、1%、17%，沃兹选择了 7 天作为第二次复习的最佳间隔。</p><p>B 阶段，新的 5 页笔记，第一次复习间隔 1 天，第二次复习间隔 7 天，第三次复习分别间隔 6、8、11、13、16 天，测得遗忘率分别为 3%、0%、0%、0%、1%，沃兹选择了 16 天作为第三次复习的最佳间隔。</p><p>C 阶段，新的 5 页笔记，前三次复习分别间隔 1、7、16 天，第四次分别间隔 20、24、28、33、38 天，遗忘率分别为 0%、3%、5%、3%、0%，沃兹选择了 35 天作为第四次复习的最佳间隔。</p><p>之后沃兹还做了第五次复习的最佳间隔的实验。但每个阶段要花费的时间差不多是前一个阶段的两倍。最终他确定了纸上算法 SM-0：</p><ul><li>I(1) = 1 天</li><li>I(2) = 7 天</li><li>I(3) = 16 天</li><li>I(4) = 35 天</li><li>for i>4: I(i) = I(i-1) * 2</li><li>将第 4 次复习后忘记的词对放到新的笔记页面中，与其他新材料一起安排重复</li></ul><p>这里的 I(i) 是指第 i 次复习使用的间隔。第五次重复开始的间隔是前一次的两倍，这是基于直觉设置的假设。在使用 SM-0 算法的两年中，沃兹收集了足够的数据来确认这一假设的合理性和准确性。</p><p>SM-0 算法的目标很清晰：在可接受的记忆遗忘程度内尽可能选择最长的间隔。它的问题也很明显：以笔记页面作为复习单位，无法跟踪更细粒度的记忆情况。</p><p>但 SM-0 的意义非凡，沃兹在 1986 年得到他的第一台电脑后，用计算机模拟了 SM-0 的学习情况，得出以下两个结论：</p><ul><li>随着时间推移，记忆总量可以不断增加，而不是减少</li><li>长期来看，学习速率几乎保持不变</li></ul><p>SM-0 让沃兹发现，记忆保留和低频重复之间是可以调和的。间隔重复并不会让学习者陷入复习的泥泞之中动弹不得。这让沃兹有了进一步优化记忆算法的信心。</p><orbit-reviewarea><orbit-prompt question=沃兹对复习间隔的期望，考虑了哪两个因素？ answer=间隔长度（与复习频率有关）和遗忘率（与记忆保留有关）></orbit-prompt>
<orbit-prompt question=为什么在沃兹的实验中，每寻找新一次的复习间隔，就要换一批新的材料？ answer=确保前几次的复习间隔都一样，控制变量></orbit-prompt>
<orbit-prompt question=SM-0的主要问题是什么？ answer=以笔记页面为复习单位，不能跟踪更细粒度的记忆状态></orbit-prompt></orbit-reviewarea><h3 id=sm-2>SM-2</h3><p>SM-0 在初期运作良好，但一些现象促使他继续改进算法：</p><ol><li>如果一个单词在第一次复习时（1天后）被遗忘，那么在接下来的第二次、第三次复习（7 天，16 天）它要比之前没有忘记的单词更容易遗忘。</li><li>那些第四次复习后忘记的词对所组成的新笔记页面，在同样的复习安排下，遗忘率更高。</li></ol><p>第一个现象让他意识到，复习并不是总能让他更熟悉材料，被遗忘的材料会更加生疏，遗忘的速度没有减缓，如果继续和同一页笔记上的材料继续按更长的间隔复习，效果并不好。</p><p>第二个现象让他意识到，材料的难度是有差异的，不同难度的内容应当要有不同的复习间隔。</p><p>于是，在 1987 年得到他的第一台电脑后，沃兹根据使用 SM-0 两年来的记录和思考，编写了 SM-2 算法。</p><p>SM-2 的算法细节如下</p><ul><li>将要记忆的知识分成尽可能小的问答对</li><li>使用以下间隔(天)重复每个问答对<ul><li>I(1) = 1</li><li>I(2) = 6</li><li>当 n > 2 时 I(n) = I(n-1) * EF<ul><li>EF(Ease-Factor)―简易度，初值为 2.5</li><li>每次复习后，nextEF = EF + (0.1-(5-q) * (0.08+(5-q) * 0.02))<ul><li>newEF―复习后 EF 的更新值</li><li>q―回忆评分，范围 0 - 5，>= 3 即回忆成功，&lt; 3 为遗忘</li></ul></li></ul></li><li>如果遗忘，将问答对的间隔重置为 I(1)，EF 保持不变</li></ul></li></ul><p>SM-2 算法将复习反馈引入到间隔安排中，复习的反馈在一定程度上反映了问答对的难度。简易度 EF 决定了间隔倍数，简易度越低，间隔倍数越小。</p><p>此时的 SM-2 算法依然基于沃兹自己的实验数据，但有两个主要改进让 SM-2 成为今天还在流行的记忆算法：</p><ol><li>对笔记页面进行更细粒度的分离，使复习安排可以精确到每个问答对，更早地分离不同难度的材料的复习周期。</li><li>引入简易度与评分，使算法有了一定的适应能力，能够根据学习者的反馈调整未来的复习规划。</li></ol><orbit-reviewarea>​ <orbit-prompt ​ question=为什么复习时被遗忘的内容，不应该安排更长的间隔？ ​ answer=被遗忘的内容，其遗忘速度没有减缓 ​></orbit-prompt>
​ <orbit-prompt ​ question=什么现象指出了材料之间存在难度差异？ ​ answer=由那些被忘记的材料所组成的笔记页面，遗忘率更高 ​></orbit-prompt>
​ <orbit-prompt ​ question=SM-2引入简易度和回忆评分的作用是什么？ ​ answer=让算法能根据学习者的反馈来调整单张卡片的复习规划 ​></orbit-prompt>
​ <orbit-prompt ​ question=对笔记页面进行更细粒度的分离，对复习安排有什么好处？ ​ answer=能更早地分离不同难度的材料的复习周期 ​></orbit-prompt></orbit-reviewarea><h3 id=sm-4>SM-4</h3><p>SM-4 的主要目标是改善 SM-2 适应能力低下的问题。虽然 SM-2 能够根据回忆评分和简易度来调整每个问答对（下文简称卡片）的复习规划，但这些调整是互相独立的。SM-2 调整新的卡片的间隔时，不会参考过去调整其他卡片的经验。</p><p>也就说，对 SM-2 来说，所有卡片在被添加时，都是一样的。不论学习者学习了多少张卡片，SM-2 对学习者依然一无所知。SM-4 通过引入间隔矩阵来代替计算间隔的函数（I(n) = I(n-1) * EF 以及 EF 更新公式）：</p><p><img class=img-zoomable src=https://supermemo.guru/images/thumb/0/0c/Matrix_of_optimum_intervals_in_SuperMemo_5.jpg/746px-Matrix_of_optimum_intervals_in_SuperMemo_5.jpg alt="Matrix of optimal intervals showed up in SuperMemo 4 in 1989 and survived to this day in SuperMemo 17 with few changes"></p><p>上述矩阵被称为最佳间隔矩阵 OI（Optimal Interval），其行索引是简易度，列索引是重复次数。其元素值是使用 SM-2 的间隔函数计算的，所以在调整 OI 矩阵之前，SM-4 与 SM-2 是等价的。</p><p>为了让新卡片能受益于旧卡片的调整经验，OI 矩阵会在复习过程中不断调整。其主要操作是：如果矩阵给出的 OI 为 X，实际复习使用的间隔为 X+Y，且回忆评分 >= 4，那么 OI 的值应当进行调整为 X 与 X+Y 之间的一个值。</p><p>这种操作的直觉是，既然在 X+Y 的间隔下学习者都能记住卡片，并且评分还挺高，那么显然是之前的 OI 太短了，我有什么理由不把原来的 OI 给调高呢？</p><p>带着这样朴素的想法，SM-4 成为了第一个能够在整体范围内适应学习者的算法。然而，SM-4 的调整并没有想象的那么成功。原因也很简单：</p><ul><li>每次复习只调整矩阵中的一项，无法在可接受的时间内明显地调整 OI 矩阵</li><li>对于较长的复习间隔，需要调整很久才能稳定</li></ul><p>为了解决上述两个问题，SM-5 应用而生。但是由于篇幅所限，本入门读物就不详述了。</p><orbit-reviewarea><orbit-prompt question=SM-2的适应能力为什么不足？ answer=对每张卡片的调整是互相独立的，不能共享调整经验></orbit-prompt>
<orbit-prompt question=SM-4引入了哪些组分来提高适应能力？ answer=最优间隔矩阵和间隔调整规则></orbit-prompt>
<orbit-prompt question=SM-4调整间隔的思路是什么？ answer=如果学习者在更长的间隔下表现良好，就提高原有间隔，反之亦然></orbit-prompt></orbit-reviewarea><h3 id=小节>小节</h3><p>1885 年发明的遗忘曲线刻画了记忆与遗忘，而 1985 年的间隔重复致力于寻找最佳的复习安排。本节介绍了经验算法的三步走：</p><ul><li>SM-0 收集实验数据确定了同一个人同一类材料的最佳复习间隔（这里的最佳是由沃兹定义的）</li><li>SM-2 将算法转换成适应计算机的形式，并引入了更细粒度的卡片和具有适应性的回忆评分与简易度</li><li>SM-4 为了让算法有适应不同学习者的能力，引入了最佳间隔矩阵和相应的间隔调整规则</li></ul><p>经验算法让我们对间隔重复有了直观的理解，但光凭经验，没有系统性的理论，想要进一步优化记忆算法是非常困难的。所以接下来，我们将进入理论环节，抽象的概念会变多，请大家坐稳手扶好，司机要提速啦！</p><h2 id=day-2-理论模型>Day 2 理论模型</h2><p>记忆算法听起来似乎是一个理论研究，但我花了大量篇幅介绍经验算法，这是何故？</p><p>因为记忆算法，是一种人工科学。记忆虽是人类生理的自然现象，但规律复习以增强记忆，却是人类自己构建的策略。</p><p>没有经验算法所支撑起的研究框架，一切理论都无从谈起。理论上的直觉，来自实践中的经验。</p><p>接下来的理论模型，也会从我们的经验出发，勿在浮沙筑高台。</p><h3 id=记忆的两个组成成分>记忆的两个组成成分</h3><p>先来道思考题：如果要你对一个材料在你记忆中的状态进行描述，你会考虑哪些因素？</p><p>在 Robert A. Bjork 之前，许多研究者使用<strong>记忆强度</strong>来表示人们对材料的记忆状态。</p><p>你觉得记忆强度这个变量能描述清楚记忆的状态么？</p><p>不妨让我们重新看看遗忘曲线：</p><p><img class=img-zoomable src=/githubpages_withorbit/%e9%95%bf%e6%9c%9f%e8%ae%b0%e5%bf%86.jpg alt=长期记忆></p><p>首先，很明显，<strong>记忆保留（回忆概率）</strong> 是描述记忆状态的一个重要变量。从我们生活经验出发，遗忘几乎是一件随机事件，谁也没有把握说，今天记住的单词，十天后一定记住，二十天后一定忘记。</p><p>有了回忆概率，就足够了么？想象一下，如果我们在上面这些遗忘曲线上划一条水平线，每个曲线都会有一个交点，它们的回忆概率相同。此时，不知道你是否察觉到，回忆概率好像无法区分这些点之间的状态区别？</p><p>没错，光靠回忆概率，我们无法区别这些材料的<strong>遗忘速度</strong>。我们需要在记忆状态中考虑到它，但是遗忘速度是一个随着时间变化的量，能否用一个与时间无关的量来刻画出它呢？</p><p>我们需要找到遗忘曲线的数学性质，才能解答这个问题。而这需要我们收集大量的数据来绘制遗忘曲线（以下数据来自墨墨背单词的<a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VAGUL0" target=_blank>开源数据集</a>）：</p><p><img class=img-zoomable src=/githubpages_withorbit/311013%e9%81%97%e5%bf%98%e6%9b%b2%e7%ba%bf.png alt=墨墨数据></p><p>从上图中，我们发现，遗忘曲线近似一条以 $e$ 为底的负指数函数，而遗忘速度就可以用负指数函数的<strong>衰减常数</strong>来刻画。</p><p>考虑到这个衰减常数很难与函数图像联系起来，我们往往会对这个衰减常数进行变换，从而得到遗忘曲线的拟合公式：</p><p>$$
R=e^{\ln{0.9}\cfrac{t}{S}}
$$</p><p>其中，R 为<strong>回忆概率</strong>（Recall），S 为<strong>记忆稳定性</strong>（Stability），t 为距离上次复习所过去的时间。</p><p>S 的大小与遗忘曲线之间的联系，可以从下图中得出：</p><p><img class=img-zoomable src=https://remnote-user-data.s3.amazonaws.com/SHk_PJ-BJfXxdhfGKdhwVHi6Al4gScMBFhFZSX1srDqzo8eaUQpyBHuTOnNzJJgcp04GbJH-uyEWm9U6wCyXX_HResGdTnGub1qf5TqFMNdevvGyBS2Hq8Bsyz_ryn1X.png alt=img></p><p>记忆稳定性恰好等于回忆概率从 100% 下降到 90% 所需的<strong>时间</strong>。（在其他学术文献中，也有使用 50% 作为基准，此时的记忆稳定性被称作记忆半衰期）</p><p>对照 Bjork 提出的记忆的两个强度——提取强度和存储强度——正好可以用回忆概率和记忆稳定性来对应。</p><p>该公式还有三个特性：</p><ol><li>当 $t = 0$ 时，$R = 100%$，表示刚刚复习时，遗忘还未开始，回忆概率为 100%；</li><li>当 $t\to\infty$ 时，$R \to 0%$，表示如果一直不复习，就会忘记几乎所有记忆；</li><li>同时，负指数函数的一阶导数也是递减的，这与遗忘先快后慢的现象一致。</li></ol><p>由此，我们得到了描述记忆的两个组成成分，但好像有什么东西被遗漏了。</p><p>回忆概率描述了遗忘的程度；记忆稳定性描述了遗忘的速度；还有什么东西没有被描述到？</p><p>复习时，遗忘曲线发生变化的这个瞬间！记忆稳定性发生了变化，而这一变化，并不单单取决于复习时的回忆概率和此时的记忆稳定性。</p><p>有什么证据吗？想想一条材料第一次学习的情况：此时的记忆稳定性为 0，回忆概率也是 0，但学习后的回忆概率变成了 100%，而记忆稳定性则视材料的某些属性而定。</p><p>也就是说，材料本身还有一些变量，会影响记忆的状态。从直觉上来看，这个变量就是材料的<strong>难度</strong>。</p><p>纳入材料难度这个变量后，我们得到了记忆三变量模型。</p><orbit-reviewarea><orbit-prompt question=为什么一个记忆强度变量无法描述清楚记忆状态？ answer=遗忘曲线不仅刻画了记忆保留，还刻画了遗忘速度，一个变量无法同时描述></orbit-prompt>
<orbit-prompt question=用于刻画记忆保留程度的变量是什么？ answer=回忆概率></orbit-prompt>
<orbit-prompt question=可以用什么函数来近似遗忘曲线？ answer=指数函数></orbit-prompt>
<orbit-prompt question=刻画记忆遗忘速度的变量是什么？ answer=记忆稳定性></orbit-prompt>
<orbit-prompt question=记忆稳定性的现实含义是什么？ answer=回忆概率从100%下降到90%所需的时间></orbit-prompt></orbit-reviewarea><h3 id=记忆三变量模型>记忆三变量模型</h3><h3 id=记忆稳定性增长>记忆稳定性增长</h3><h3 id=记忆复杂性>记忆复杂性</h3><h2 id=day-3-前沿进展>Day 3 前沿进展</h2><h3 id=数据收集>数据收集</h3><h3 id=dsr模型>DSR模型</h3><h3 id=ssp-mmc算法>SSP-MMC算法</h3><h2 id=总结>总结</h2></div></article><div class="license markdown-body"><blockquote><p>除特殊注明部分，本站内容采用 <a rel=license href=http://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank>CC BY-NC-SA 4.0</a> 进行许可。</p></blockquote></div><div class=post-comment data-comment=utterances><span class=post-comment-notloaded><i class="iconfont icon-chatbox-ellipses-sharp"></i>&nbsp;查看评论</span>
<script>function loadComment(){var n=document.querySelector(".post-comment"),e,t=document.body.getAttribute("data-theme");t==="auto"?t=window.matchMedia("(prefers-color-scheme: dark)").matches?"photon-dark":"github-light":t=t==="dark"?"photon-dark":"github-light",e=document.createElement("script"),e.src="https://utteranc.es/client.js",e.setAttribute("repo","L-M-Sherlock/githubpages_withorbit"),e.setAttribute("issue-term","pathname"),e.setAttribute("theme",t),e.setAttribute("crossorigin","anonymous"),e.setAttribute("async",''),document.querySelector(".post-comment").appendChild(e),document.querySelector("span.post-comment-notloaded").setAttribute("style","display: none;")}</script></div></div><aside class="col-12 col-md-3 float-left sidebar"><div class="sidebar-item sidebar-pages"><h3>页面</h3><ul><li><a href=/githubpages_withorbit/>Home</a></li><li><a href=/githubpages_withorbit/archives/>Archives</a></li><li><a href=/githubpages_withorbit/about/>About</a></li><li><a href=/githubpages_withorbit/search/>Search</a></li><li><a href=/githubpages_withorbit/index.xml>RSS</a></li></ul></div><div class="sidebar-item sidebar-links"><h3>链接</h3><ul><li><a href=https://github.com/L-M-Sherlock target=_blank><span>GitHub</span></a></li><li><a href=https://www.zhihu.com/people/L.M.Sherlock target=_blank><span>ZhiHu</span></a></li><li><a href=https://space.bilibili.com/5301648 target=_blank><span>bilibili</span></a></li></ul></div><div class="sidebar-item sidebar-tags"><h3>标签</h3><div><span><a href=/githubpages_withorbit/tags/test/>test</a></span>
<span><a href=/githubpages_withorbit/tags/%E5%88%B6%E5%8D%A1%E6%96%B9%E6%B3%95/>制卡方法</a></span>
<span><a href=/githubpages_withorbit/tags/%E5%8E%9F%E5%88%9B/>原创</a></span>
<span><a href=/githubpages_withorbit/tags/%E7%BF%BB%E8%AF%91/>翻译</a></span>
<span><a href=/githubpages_withorbit/tags/%E9%97%B4%E9%9A%94%E9%87%8D%E5%A4%8D/>间隔重复</a></span></div></div><div class="sidebar-item sidebar-toc"><h3>目录</h3><nav id=TableOfContents><ul><li><a href=#引言>引言</a></li><li><a href=#day-1-经验算法>Day 1 经验算法</a><ul><li><a href=#间隔重复>间隔重复</a></li><li><a href=#sm-0>SM-0</a></li><li><a href=#sm-2>SM-2</a></li><li><a href=#sm-4>SM-4</a></li><li><a href=#小节>小节</a></li></ul></li><li><a href=#day-2-理论模型>Day 2 理论模型</a><ul><li><a href=#记忆的两个组成成分>记忆的两个组成成分</a></li><li><a href=#记忆三变量模型>记忆三变量模型</a></li><li><a href=#记忆稳定性增长>记忆稳定性增长</a></li><li><a href=#记忆复杂性>记忆复杂性</a></li></ul></li><li><a href=#day-3-前沿进展>Day 3 前沿进展</a><ul><li><a href=#数据收集>数据收集</a></li><li><a href=#dsr模型>DSR模型</a></li><li><a href=#ssp-mmc算法>SSP-MMC算法</a></li></ul></li><li><a href=#总结>总结</a></li></ul></nav></div></aside></div><div class=btn><div class=btn-menu id=btn-menu><i class="iconfont icon-grid-sharp"></i></div><div class=btn-toggle-mode><i class="iconfont icon-contrast-sharp"></i></div><div class=btn-scroll-top><i class="iconfont icon-chevron-up-circle-sharp"></i></div></div><aside class=sidebar-mobile style=display:none><div class=sidebar-wrapper><div class="sidebar-item sidebar-pages"><h3>页面</h3><ul><li><a href=/githubpages_withorbit/>Home</a></li><li><a href=/githubpages_withorbit/archives/>Archives</a></li><li><a href=/githubpages_withorbit/about/>About</a></li><li><a href=/githubpages_withorbit/search/>Search</a></li><li><a href=/githubpages_withorbit/index.xml>RSS</a></li></ul></div><div class="sidebar-item sidebar-links"><h3>链接</h3><ul><li><a href=https://github.com/L-M-Sherlock target=_blank><span>GitHub</span></a></li><li><a href=https://www.zhihu.com/people/L.M.Sherlock target=_blank><span>ZhiHu</span></a></li><li><a href=https://space.bilibili.com/5301648 target=_blank><span>bilibili</span></a></li></ul></div><div class="sidebar-item sidebar-tags"><h3>标签</h3><div><span><a href=/githubpages_withorbit/tags/test/>test</a></span>
<span><a href=/githubpages_withorbit/tags/%E5%88%B6%E5%8D%A1%E6%96%B9%E6%B3%95/>制卡方法</a></span>
<span><a href=/githubpages_withorbit/tags/%E5%8E%9F%E5%88%9B/>原创</a></span>
<span><a href=/githubpages_withorbit/tags/%E7%BF%BB%E8%AF%91/>翻译</a></span>
<span><a href=/githubpages_withorbit/tags/%E9%97%B4%E9%9A%94%E9%87%8D%E5%A4%8D/>间隔重复</a></span></div></div><div class="sidebar-item sidebar-toc"><h3>目录</h3><nav id=TableOfContents><ul><li><a href=#引言>引言</a></li><li><a href=#day-1-经验算法>Day 1 经验算法</a><ul><li><a href=#间隔重复>间隔重复</a></li><li><a href=#sm-0>SM-0</a></li><li><a href=#sm-2>SM-2</a></li><li><a href=#sm-4>SM-4</a></li><li><a href=#小节>小节</a></li></ul></li><li><a href=#day-2-理论模型>Day 2 理论模型</a><ul><li><a href=#记忆的两个组成成分>记忆的两个组成成分</a></li><li><a href=#记忆三变量模型>记忆三变量模型</a></li><li><a href=#记忆稳定性增长>记忆稳定性增长</a></li><li><a href=#记忆复杂性>记忆复杂性</a></li></ul></li><li><a href=#day-3-前沿进展>Day 3 前沿进展</a><ul><li><a href=#数据收集>数据收集</a></li><li><a href=#dsr模型>DSR模型</a></li><li><a href=#ssp-mmc算法>SSP-MMC算法</a></li></ul></li><li><a href=#总结>总结</a></li></ul></nav></div></div></aside></main><footer><div class="container-lg clearfix"><div class="col-12 footer"><p>除特殊注明部分，本站内容采用 <a rel=license href=http://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank>CC BY-NC-SA 4.0</a> 进行许可。</p><span>&copy; 2022-2022
<a href=https://l-m-sherlock.github.io/githubpages_withorbit/>Jarrett Ye</a>
| <a href=https://github.com/L-M-Sherlock/githubpages_withorbit>Source code</a>
| 基于 <a href=https://github.com/dsrkafuu/hugo-theme-fuji/ target=_blank>Fuji-v2</a> & <a href=https://gohugo.io/ target=_blank>Hugo</a> 构建</span></div></div></footer><script defer src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/components/prism-core.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/plugins/autoloader/prism-autoloader.min.js></script>
<script defer src=/githubpages_withorbit/assets/js/fuji.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css><script src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js></script>
<script>renderMathInElement(document.querySelector("div.content"),{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})</script><script type=module src=https://js.withorbit.com/orbit-web-component.js></script></body></html>